7 - Com o desenvolvimento das empresas e o seu crescimento gradual, os seus terminais de dispositivos continuam a expandir-se em termos de tipos, números e gamas de aplicações. A forma de proteção da segurança do terminal está se tornando cada vez mais severa e vulnerabilidades e vírus dos terminais surgem indefinidamente. Uma rede corporativa e um ambiente de terminal de alta qualidade, eficiente e seguro são uma garantia importante para o bom desenvolvimento das empresas. No entanto, os métodos de monitorização comummente utilizados dos terminais de equipamentos existentes, especialmente os métodos de detecção de tráfego encriptado, têm sido incapazes de satisfazer as necessidades de algumas empresas de monitorização em tempo real, identificação rápida e bloqueio atempado de comportamentos de alto risco dos terminais. Neste artigo, é proposto um método de monitoramento de tráfego criptografado para usuários finais para realizar a detecção anormal de tráfego de usuários. O modelo de rede neural profunda é usado para extrair recursos de dados de comunicação e recursos de tráfego anormal para comparação de similaridade, a fim de julgar se é tráfego anormal.

6 - Recentemente, muitas empresas migraram seus dados para a nuvem usando serviços de sincronização e compartilhamento de arquivos (FSS), que foram implantados para usuários móveis. No entanto, as soluções Bring-Your-Own-Device (BYOD) para dispositivos móveis cada vez mais implantados também levantaram um novo desafio sobre como evitar que os usuários abusem do serviço FSS. Neste artigo, abordamos esse problema usando um novo modelo de sistema envolvendo abordagens de detecção, rastreamento e revogação de anomalias. A solução apresentada aplica um novo sistema criptográfico baseado em chave pública de limite, denominado criptografia hierárquica parcialmente ordenada (PHE), que implementa uma hierarquia de chaves de ordem parcial e é semelhante à hierarquia de papéis amplamente utilizada no RBAC. O PHE fornece dois mecanismos principais de segurança, ou seja, rastreamento de traidores e revogação de chaves, o que pode melhorar muito a eficiência em comparação com abordagens anteriores. A análise de segurança e desempenho mostra que o PHE é uma criptografia de limite comprovadamente segura e oferece os seguintes benefícios importantes de gerenciamento e desempenho: pode prometer rastrear com eficiência todas as possíveis coalizões de traidores e apoiar a revogação pública não apenas para os usuários, mas também para os grupos especificados.

5 - A detecção de anomalias é uma tarefa essencial de mineração de dados para alcançar segurança e confiabilidade em sistemas computacionais. Os logs são uma fonte de dados comum e importante para métodos de detecção de anomalias em quase todos os sistemas de computador. Estudos recentes concentraram-se predominantemente em métodos de aprendizagem profunda de uma classe em representações de log especificadas manualmente. A principal limitação é que esses modelos não são capazes de aprender representações de log que descrevem as diferenças semânticas entre logs normais e de anomalias, levando a uma generalização pobre em logs não vistos. Propomos o Logsy, um método baseado em classificação para aprender representações de log que permitem distinguir entre dados normais de log do sistema e amostras de anomalias de conjuntos de dados de log auxiliares, facilmente acessíveis via internet. A ideia por trás de tal abordagem para detecção de anomalias é que o conjunto de dados auxiliares seja suficientemente informativo para melhorar a representação dos dados normais, mas diversificado para regularizar contra overfitting e melhorar a generalização. Realizamos vários experimentos em conjuntos de dados disponíveis publicamente para avaliar o desempenho e as propriedades, onde mostramos uma melhoria de 0,25 em F1 em comparação aos métodos anteriores.

4 - A descoberta não supervisionada de anomalias em dados de fluxo é um tópico de pesquisa com muitas aplicações práticas. No entanto, em muitos casos, não é fácil coletar dados de treinamento suficientes com anomalias rotuladas para aprendizagem supervisionada de um detector de anomalias, a fim de implantá-lo posteriormente para identificação de anomalias reais em dados de streaming. Portanto, é importante projetar detectores de anomalias que possam detectar corretamente anomalias sem acesso a dados de treinamento rotulados. Nossa ideia é adaptar o classificador Online Evolution Spiking Neural Network (OeSNN) para a tarefa de detecção de anomalias. Como resultado, oferecemos um algoritmo de rede neural de pico em evolução on-line para detecção de anomalias não supervisionadas (OeSNN-UAD), que, ao contrário do OeSNN, funciona de forma não supervisionada e não separa os neurônios de saída em classes de decisão disjuntas. OeSNN-UAD usa nosso novo método proposto de detecção de anomalias em duas etapas. Além disso, derivamos novas propriedades teóricas do modelo neuronal e da codificação da camada de entrada do OeSNN, que permitem uma detecção mais eficaz e eficiente de anomalias em nossa abordagem OeSNN-UAD. O detector OeSNN-UAD proposto foi comparado experimentalmente com detectores não supervisionados e semissupervisionados de última geração de anomalias em dados de fluxo dos repositórios Numenta Anomaly Benchmark e Yahoo Anomaly Datasets. Nossa abordagem supera as demais soluções fornecidas na literatura no caso de fluxos de dados do repositório Numenta Anomaly Benchmark. Além disso, no caso de arquivos de dados reais do repositório Yahoo Anomaly Benchmark, o OeSNN-UAD supera outros algoritmos selecionados, enquanto no caso de arquivos de dados sintéticos do Yahoo Anomaly Benchmark, fornece resultados competitivos aos resultados recentemente relatados na literatura.

3 - Os avanços tecnológicos e o aumento da interconectividade levaram a um risco maior de ameaças até então desconhecidas. Portanto, a Cyber Security emprega sistemas de detecção de intrusões que monitoram continuamente as linhas de registro para proteger os sistemas contra tais ataques. As abordagens existentes usam métricas de string para agrupar linhas semelhantes em clusters e detectar linhas diferentes como valores discrepantes. No entanto, tais métodos produzem apenas visualizações estáticas dos dados e não incorporam suficientemente a natureza dinâmica dos logs. As mudanças na infra-estrutura tecnológica exigem, portanto, frequentemente reformas de cluster. Além disso, tais abordagens não são adequadas para detectar anomalias relacionadas a frequências, alterações periódicas e interdependências de linhas logarítmicas. Portanto, propomos uma metodologia dinâmica de detecção de anomalias em arquivos de log que agrupa gradativamente as linhas de log dentro de janelas de tempo. Assim, um novo mecanismo de agrupamento estabelece ligações entre coleções de agrupamentos que de outra forma seriam isoladas. As técnicas de evolução de cluster analisam clusters de janelas de tempo vizinhas e determinam transições como divisões ou fusões. Um algoritmo de autoaprendizagem detecta então anomalias no comportamento temporal desses clusters em evolução, analisando métricas derivadas de seus desenvolvimentos. Aplicamos um protótipo em um cenário ilustrativo que consiste em um arquivo de log contendo anomalias conhecidas. Assim, investigamos as influências de certos parâmetros na capacidade de detecção e no tempo de execução. A avaliação deste cenário mostra que 61,8% das alterações dinâmicas dos clusters de linhas de log são identificadas corretamente, enquanto a taxa de falsos alarmes é de apenas 0,7%. A capacidade de detectar eficientemente essas anomalias enquanto se ajusta às mudanças no ambiente do sistema sugere a aplicabilidade da abordagem introduzida.

2 - Os sistemas de computador cresceram em complexidade a tal ponto que a inspeção manual do comportamento do sistema para fins de detecção de mau funcionamento se tornou inviável. Como esses sistemas geram registros volumosos de suas atividades, a análise deles conduzida por máquina é uma necessidade crescente com diversas soluções já existentes. Eles dependem em grande parte de recursos feitos à mão, exigem pré-processamento de log bruto e extração de recursos ou usam aprendizado supervisionado, necessitando de um conjunto de dados de log rotulado que nem sempre é facilmente obtido. Propomos um modelo de autoencoder profundo em duas partes com unidades LSTM que não requer recursos artesanais, nenhum pré-processamento de dados, pois funciona em texto bruto e gera uma pontuação de anomalia para cada entrada de log. Essa pontuação de anomalia representa a raridade de um evento de log tanto em termos de conteúdo quanto de contexto temporal. O modelo foi treinado e testado em um conjunto de dados de logs HDFS contendo 2 milhões de linhas brutas, das quais metade foi usada para treinamento e a outra metade para teste. Embora este modelo não possa corresponder ao desempenho de um classificador binário supervisionado, pode ser uma ferramenta útil como filtro grosso para inspeção manual de arquivos de log onde um conjunto de dados rotulado não está disponível.

1 - A detecção automática de anomalias na mineração de dados tem uma ampla gama de aplicações, como detecção de fraudes, monitoramento da integridade do sistema, detecção de falhas, sistemas de detecção de eventos em redes de sensores e assim por diante. O principal desafio relacionado a tal problema é o desconhecimento da natureza da anomalia. Portanto, é impossível utilizar técnicas clássicas de aprendizado de máquina para treinar o modelo, pois não temos rótulos de séries temporais com anomalia. Para séries temporais periódicas é aconselhável usar a decomposição STL do sinal. Nesse caso, a tarefa de detecção de anomalias é reduzida à detecção de picos residuais. Se a série temporal não for periódica (por exemplo, preço forex ou som), a única maneira é usar métodos de aprendizado de máquina. Um dos melhores métodos de aprendizado de máquina é a detecção de anomalias baseada em codificador automático. Um autoencoder é um tipo de rede neural artificial usada para aprender codificações de dados eficientes de maneira não supervisionada. O objetivo de um autoencoder é aprender uma representação (codificação) para um conjunto de dados, normalmente para redução de dimensionalidade, treinando a rede para ignorar o “ruído” do sinal. O método de detecção de anomalias não supervisionadas baseado em autoencoders foi testado em dois tipos de dados: vários conjuntos de dados de sinais artificiais e detecção de conjuntos de dados de eventos sonoros raros.